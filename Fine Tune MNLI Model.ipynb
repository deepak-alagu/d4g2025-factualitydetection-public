{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "i_cR9O2DgyP4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR29Vnejrvea"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "# Core imports\n",
        "import os, json, random, math\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EbzqK2zrvei"
      },
      "outputs": [],
      "source": [
        "import gc, torch\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminaries"
      ],
      "metadata": {
        "id": "HYvZU0aFg5s3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LReSM61lrvej"
      },
      "outputs": [],
      "source": [
        "# -----------------------\n",
        "# Config\n",
        "# -----------------------\n",
        "MODEL_NAME = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"\n",
        "LABELS = [\"factual\", \"contradiction\", \"irrelevant\"]\n",
        "\n",
        "# TRAIN_PATH = \"/content/train.json\"\n",
        "TEST_PATH  = \"/content/test.json\"\n",
        "TRAIN_PATH = \"/content/my_train.json\"\n",
        "NO_TRAIN_PATH = \"/content/my_test.json\"\n",
        "VAL_PATH = \"/content/my_val.json\"\n",
        "\n",
        "\n",
        "OUT_DIR = \"outputs_kfold\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "N_SPLITS = 5\n",
        "SEED = 42\n",
        "\n",
        "MAX_LENGTH = 256\n",
        "LR = 2e-5\n",
        "EPOCHS = 2\n",
        "TRAIN_BATCH = 8\n",
        "EVAL_BATCH = 16\n",
        "WEIGHT_DECAY = 0.01\n",
        "WARMUP_RATIO = 0.06\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", DEVICE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNl-N4ctrvek"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed: int = 42) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUOCTDKorvem"
      },
      "outputs": [],
      "source": [
        "def load_json_records(path: str) -> List[Dict]:\n",
        "    # supports list-of-dicts, or dict-wrapped list-of-dicts\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "    if isinstance(data, list):\n",
        "        return data\n",
        "    if isinstance(data, dict):\n",
        "        for v in data.values():\n",
        "            if isinstance(v, list):\n",
        "                return v\n",
        "    raise ValueError(f\"Unsupported JSON format in {path}\")\n",
        "\n",
        "def normalize_label(x) -> str:\n",
        "    return str(x).strip().lower()\n",
        "\n",
        "def build_label_maps(labels: List[str]) -> Tuple[Dict[str, int], Dict[int, str]]:\n",
        "    labels_norm = [normalize_label(l) for l in labels]\n",
        "    label2id = {l:i for i,l in enumerate(labels_norm)}\n",
        "    id2label = {i:l for l,i in label2id.items()}\n",
        "    return label2id, id2label\n",
        "\n",
        "label2id, id2label = build_label_maps(LABELS)\n",
        "label2id, id2label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHC-FKArven"
      },
      "outputs": [],
      "source": [
        "def prepare_dataframe(records: List[Dict], is_train: bool) -> pd.DataFrame:\n",
        "    df = pd.DataFrame(records)\n",
        "\n",
        "    # expected keys (most common in this competition)\n",
        "    # - question, context, answer, type\n",
        "    # but we make this robust to variations.\n",
        "    if \"answer\" not in df.columns:\n",
        "        raise ValueError(f\"Missing 'answer' column. Found columns: {list(df.columns)}\")\n",
        "\n",
        "    # Build premise = context + question\n",
        "    if \"context\" in df.columns:\n",
        "        ctx = df[\"context\"].fillna(\"\").astype(str)\n",
        "    elif \"premise\" in df.columns:\n",
        "        ctx = df[\"premise\"].fillna(\"\").astype(str)\n",
        "    else:\n",
        "        raise ValueError(f\"Missing 'context' (or 'premise') column. Found columns: {list(df.columns)}\")\n",
        "\n",
        "    if \"question\" in df.columns:\n",
        "        q = df[\"question\"].fillna(\"\").astype(str)\n",
        "    else:\n",
        "        # fallback if question key is different\n",
        "        # common alternates: 'query', 'prompt'\n",
        "        for alt in [\"query\", \"prompt\"]:\n",
        "            if alt in df.columns:\n",
        "                q = df[alt].fillna(\"\").astype(str)\n",
        "                break\n",
        "        else:\n",
        "            # if no question exists, just use context as premise\n",
        "            q = pd.Series([\"\"] * len(df))\n",
        "\n",
        "    df[\"premise_text\"] = (ctx + \"\\n\\nQuestion: \" + q).str.strip()\n",
        "    df[\"hypothesis_text\"] = df[\"answer\"].fillna(\"\").astype(str)\n",
        "\n",
        "    if is_train:\n",
        "        if \"type\" not in df.columns:\n",
        "            raise ValueError(f\"Missing 'type' label column. Found columns: {list(df.columns)}\")\n",
        "        df[\"label\"] = df[\"type\"].apply(normalize_label).map(label2id)\n",
        "        if df[\"label\"].isna().any():\n",
        "            bad = df[df[\"label\"].isna()][\"type\"].unique()[:10]\n",
        "            raise ValueError(f\"Found unknown labels in train: {bad}. Expected {LABELS}\")\n",
        "        df[\"label\"] = df[\"label\"].astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "train_records = load_json_records(TRAIN_PATH)\n",
        "no_train_records = load_json_records(NO_TRAIN_PATH)\n",
        "test_records  = load_json_records(TEST_PATH)\n",
        "val_records = load_json_records(VAL_PATH)\n",
        "\n",
        "train_df = prepare_dataframe(train_records, is_train=True)\n",
        "no_train_df = prepare_dataframe(no_train_records, is_train=False)\n",
        "test_df  = prepare_dataframe(test_records,  is_train=False)\n",
        "val_df = prepare_dataframe(val_records, is_train=False)\n",
        "\n",
        "train_df.head(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiGeN4R7rveo"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_dataset(df: pd.DataFrame, with_labels: bool) -> Dataset:\n",
        "    ds = Dataset.from_pandas(df.reset_index(drop=True))\n",
        "\n",
        "    def _tok(batch):\n",
        "        return tokenizer(\n",
        "            batch[\"premise_text\"],\n",
        "            batch[\"hypothesis_text\"],\n",
        "            truncation=True,\n",
        "            max_length=MAX_LENGTH,\n",
        "        )\n",
        "\n",
        "    remove_cols = [c for c in ds.column_names if c not in [\"premise_text\",\"hypothesis_text\",\"label\"]]\n",
        "    ds = ds.map(_tok, batched=True, remove_columns=remove_cols)\n",
        "    if with_labels:\n",
        "        ds = ds.rename_column(\"label\", \"labels\")\n",
        "    ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\"] + ([\"labels\"] if with_labels else []))\n",
        "    return ds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEglD20Trveq"
      },
      "outputs": [],
      "source": [
        "def make_model():\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,\n",
        "                                                               num_labels=len(LABELS),\n",
        "        id2label=id2label,\n",
        "        label2id=label2id,)\n",
        "\n",
        "    try:\n",
        "        model.gradient_checkpointing_enable(\n",
        "            gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
        "        )\n",
        "    except TypeError:\n",
        "        # older transformers: no kwargs support, fallback\n",
        "        model.gradient_checkpointing_enable()\n",
        "\n",
        "    model.config.use_cache = False\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, y_true = eval_pred\n",
        "    y_pred = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(LABELS))))\n",
        "    return {\n",
        "        \"accuracy\": float(acc),\n",
        "        \"macro_f1\": float(macro_f1),\n",
        "        \"confusion_matrix\": cm.tolist(),\n",
        "    }\n",
        "\n",
        "import inspect\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "def trainer_args(run_name: str, out_dir: str) -> TrainingArguments:\n",
        "    sig = inspect.signature(TrainingArguments.__init__)\n",
        "    allowed = set(sig.parameters.keys())\n",
        "\n",
        "    # Map arg name changes across transformers versions\n",
        "    if \"eval_strategy\" in allowed and \"evaluation_strategy\" not in allowed:\n",
        "        eval_key = \"eval_strategy\"\n",
        "    else:\n",
        "        eval_key = \"evaluation_strategy\"\n",
        "\n",
        "    kwargs = dict(\n",
        "        output_dir=out_dir,\n",
        "        run_name=run_name,\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=32,\n",
        "        num_train_epochs=4,\n",
        "        # num_train_epochs=4,\n",
        "        weight_decay=0.01,\n",
        "        warmup_ratio=0.06,\n",
        "        fp16=True,\n",
        "\n",
        "        # evaluation/checkpointing/logging\n",
        "        **{eval_key: \"epoch\"},\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=50,\n",
        "\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"macro_f1\",\n",
        "        greater_is_better=True,\n",
        "\n",
        "        report_to=\"none\",\n",
        "        seed=42,\n",
        "    )\n",
        "\n",
        "    # Drop anything unsupported by this transformers version\n",
        "    kwargs = {k: v for k, v in kwargs.items() if k in allowed}\n",
        "\n",
        "    # If the version lacks run_name, drop it\n",
        "    # (filter above already does this, but keeping comment for clarity)\n",
        "    return TrainingArguments(**kwargs)\n",
        "\n",
        "\n",
        "def predict_probs(trainer: Trainer, ds: Dataset, batch_size: int = 64):\n",
        "    # Trainer.predict uses the trainer's args eval batch size, but we can override with a temp args if needed.\n",
        "    preds = trainer.predict(ds)\n",
        "    logits = preds.predictions\n",
        "    probs = torch.softmax(torch.tensor(logits), dim=-1).cpu().numpy()\n",
        "    pred_ids = probs.argmax(axis=-1)\n",
        "    conf = probs.max(axis=-1)\n",
        "    return pred_ids, conf, probs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RovbHUHMrver"
      },
      "source": [
        "## Train on train data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nlU6WGxrvev"
      },
      "outputs": [],
      "source": [
        "full_dir = os.path.join(OUT_DIR, \"full_train\")\n",
        "os.makedirs(full_dir, exist_ok=True)\n",
        "\n",
        "full_train_ds = tokenize_dataset(train_df, with_labels=True)\n",
        "\n",
        "full_model = make_model()\n",
        "full_args = TrainingArguments(\n",
        "    output_dir=full_dir,\n",
        "    learning_rate=LR,\n",
        "    # num_train_epochs=EPOCHS,\n",
        "    num_train_epochs=4,\n",
        "\n",
        "    per_device_train_batch_size=TRAIN_BATCH,\n",
        "    per_device_eval_batch_size=EVAL_BATCH,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    warmup_ratio=WARMUP_RATIO,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=4,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    seed=SEED,\n",
        ")\n",
        "\n",
        "full_trainer = Trainer(\n",
        "    model=full_model,\n",
        "    args=full_args,\n",
        "    train_dataset=full_train_ds,\n",
        "    eval_dataset=full_train_ds,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "initial_metrics = full_trainer.evaluate()\n",
        "initial_loss = initial_metrics[\"eval_loss\"]\n",
        "# full_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callback functions to record the loss at the end of every epoch"
      ],
      "metadata": {
        "id": "ZYOOu_S4fF6o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0rfsUIas4aS"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainerCallback\n",
        "\n",
        "class LossRecorderCallback(TrainerCallback):\n",
        "    def __init__(self):\n",
        "        self.epoch_losses = []\n",
        "\n",
        "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
        "        if \"eval_loss\" in metrics:\n",
        "            self.epoch_losses.append({\n",
        "                \"epoch\": state.epoch,\n",
        "                \"eval_loss\": metrics[\"eval_loss\"]\n",
        "            })\n",
        "\n",
        "class SaveAtEpoch2Callback(TrainerCallback):\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        if int(state.epoch) == 2:\n",
        "            control.should_save = True\n",
        "        return control\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model and saving the epoch losses"
      ],
      "metadata": {
        "id": "ro-mWJFBfK9w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk_SmABJs6Ym"
      },
      "outputs": [],
      "source": [
        "loss_cb = LossRecorderCallback()\n",
        "save_cb = SaveAtEpoch2Callback()\n",
        "\n",
        "full_trainer.add_callback(loss_cb)\n",
        "full_trainer.add_callback(save_cb)\n",
        "\n",
        "full_trainer.train()\n",
        "\n",
        "with open(os.path.join(full_dir, \"epoch_losses.json\"), \"w\") as f:\n",
        "    json.dump({\n",
        "        \"initial_loss\": initial_loss,\n",
        "        \"epoch_losses\": loss_cb.epoch_losses\n",
        "    }, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the finetuned model on no_train_df (the 'test set') and val_df (the 'validation set')"
      ],
      "metadata": {
        "id": "6sdNc3Y8fQDu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwTSnVLBxI43"
      },
      "outputs": [],
      "source": [
        "# Predict on val_df\n",
        "# val_df, no_train_df\n",
        "\n",
        "train_pred_ids, train_conf, train_probs = predict_probs(full_trainer, tokenize_dataset(val_df, with_labels=False))\n",
        "\n",
        "train_pred_df = no_train_df.copy()\n",
        "train_pred_df[\"pred_id\"] = train_pred_ids\n",
        "train_pred_df[\"pred_label\"] = [id2label[i] for i in train_pred_ids]\n",
        "train_pred_df[\"pred_conf\"] = train_conf\n",
        "for i,lbl in enumerate(LABELS):\n",
        "    train_pred_df[f\"prob_{lbl}\"] = train_probs[:, i]\n",
        "\n",
        "train_pred_path = os.path.join(OUT_DIR, \"epoch_4_val_predictions.csv\")\n",
        "train_pred_df.to_csv(train_pred_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the finetuned model at different epochs on no_train_df and val_df for evaluation and testing purposes"
      ],
      "metadata": {
        "id": "WYvya0PUfVU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, Trainer\n",
        "\n",
        "ckpt_path = os.path.join(full_dir, \"checkpoint-9600\")\n",
        "\n",
        "model_7275 = AutoModelForSequenceClassification.from_pretrained(\n",
        "    ckpt_path,\n",
        "    num_labels=len(LABELS)\n",
        ")\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "infer_args = TrainingArguments(\n",
        "    output_dir=full_dir,\n",
        "    per_device_eval_batch_size=EVAL_BATCH,\n",
        "    report_to=\"none\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "trainer_7275 = Trainer(\n",
        "    model=model_7275,\n",
        "    args=infer_args,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "no_train_ds = tokenize_dataset(no_train_df, with_labels=False)\n",
        "\n",
        "pred_ids, conf, probs = predict_probs(trainer_7275, no_train_ds)\n",
        "pred_df = no_train_df.copy()\n",
        "pred_df[\"pred_id\"] = pred_ids\n",
        "pred_df[\"pred_label\"] = [id2label[i] for i in pred_ids]\n",
        "pred_df[\"pred_conf\"] = conf\n",
        "\n",
        "for i, lbl in enumerate(LABELS):\n",
        "    pred_df[f\"prob_{lbl}\"] = probs[:, i]\n",
        "\n",
        "pred_df.to_csv(\n",
        "    os.path.join(OUT_DIR, \"epoch_4_2_no_train_predictions.csv\"),\n",
        "    index=False\n",
        ")"
      ],
      "metadata": {
        "id": "pF-L5OM918CS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 9200960,
          "sourceId": 14406423,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 9207151,
          "sourceId": 14415664,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31236,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}